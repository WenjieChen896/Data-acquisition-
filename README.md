#数据采集的一些整理
数据总会面临数据丢失的问题，因此可以设计大数据全日志链路大盘数据监控平台系统，这个系统主要排查数据丢失的问题。

大数据数据从哪来，通过数据采集来。
标准的日志上报埋点，或着一些日志数据清洗采集过来。
不管怎么说，数据发出来的地方，都是tcp/udp或者http，或者file。
首先说http上来的数据
现在互联网公司统一大数据接收是靠一层CLB或者其他的，阿里，腾讯提供的类似负载均衡的东西。。
然后就到公司内部的服务器上，现在用的最多的nginx
接下来的做法就有区别了，取决于公司的性质
B站的数据http过来之后，使用nginx转发到分布式的服务上面，拼多多的数据http过来之后首先是落盘
这两者之间的优缺点中，最大的区别就是钱（log——format），有钱落盘！！
到采集系统了，目前采集互联网目前最多的便是flume，一般会用两层flume，最后数据会到缓存队列等等
这个过程中怎么知道数据一条都没丢
怎样设计能够感知每一条数据
那么问题来了，很多数据都在一个地方，必须要区分出来，中间流至少两层flume和一层kafka
任何一个中间件都可能会丢数据
nginx那层我们不考虑，那层丢了是运维的锅。
首先第一件就是区分业务，b站和拼多多的思路也不一样
B站是统一域名，每类数据会有唯一的编号
拼多多没类数据分域打，通过落盘不同文件
然后及时数据统计了
统计，需要一个service端
而且数据都是海量数据，要计算每一台机器数据量有没有丢失
所以计算的维度是  分类 * 机器IP * 计数类型（服务端思想）
接下是组件的数据了
组件中的数据，因为要精确到每一台机器上面，我要知道这些数据在哪台机器上面
组件中的数据，可以改源码（flume和kafka源码很熟的话）
简单说一下就是设计一个环形数组和补时数组
正常的数据都会有时间戳，要么是基于这条数据的时间戳，要么是基于nginx拦截到数据的时间戳，这个都可以改
环形数组用来存入一小时内每分钟的条数，定时上报就行
补时数组比较麻烦，因为要考虑回补数据
要把老时间的数据补在那个位置上
这里搞定，就能知道每个机器有没有丢数据（可以更具日志上的时间，也可以按读取的时间）
接下来就是数据落盘
当然在改组件内部，改源码要有好的代码功底，不然线程消耗会有问题
然后有了所有监控数据，做什么都可以。比如同比环比，趋势预测，以及告警和其他
上面那层就不说了，五花八门一个大盘
很多中间件本省自带metric，但是很多都不支持业务上的metric
比如说kafka的offset，但是不能做到基于业务的metric，想要同步起来，还是要在一个系统里
比如flume，本身又分为source、channel，sink，我想把这些组件和kafka的监控结合起来，以及套用其他东西
最后就能看到他们需要多少数据，经过大数据各个环节有多少条，最后输出多少条，每条数据到达组件的时间点
能监控数据同环比，有异常能第一时间电话告警

#数据采集的一些整理
数据总会面临数据丢失的问题，因此可以设计大数据全日志链路大盘数据监控平台系统，这个系统主要排查数据丢失的问题。

大数据数据从哪来，通过数据采集来。
标准的日志上报埋点，或着一些日志数据清洗采集过来。
不管怎么说，数据发出来的地方，都是tcp/udp或者http，或者file。
首先说http上来的数据
现在互联网公司统一大数据接收是靠一层CLB或者其他的，阿里，腾讯提供的类似负载均衡的东西。。
然后就到公司内部的服务器上，现在用的最多的nginx
接下来的做法就有区别了，取决于公司的性质
B站的数据http过来之后，使用nginx转发到分布式的服务上面，拼多多的数据http过来之后首先是落盘
这两者之间的优缺点中，最大的区别就是钱（log——format），有钱落盘！！
到采集系统了，目前采集互联网目前最多的便是flume，一般会用两层flume，最后数据会到缓存队列等等
这个过程中怎么知道数据一条都没丢
怎样设计能够感知每一条数据
那么问题来了，很多数据都在一个地方，必须要区分出来，中间流至少两层flume和一层kafka
任何一个中间件都可能会丢数据
nginx那层我们不考虑，那层丢了是运维的锅。
首先第一件就是区分业务，b站和拼多多的思路也不一样
B站是统一域名，每类数据会有唯一的编号
拼多多没类数据分域打，通过落盘不同文件
然后及时数据统计了
统计，需要一个service端
而且数据都是海量数据，要计算每一台机器数据量有没有丢失
所以计算的维度是  分类 * 机器IP * 计数类型（服务端思想）
接下是组件的数据了
组件中的数据，因为要精确到每一台机器上面，我要知道这些数据在哪台机器上面
组件中的数据，可以改源码（flume和kafka源码很熟的话）
简单说一下就是设计一个环形数组和补时数组
正常的数据都会有时间戳，要么是基于这条数据的时间戳，要么是基于nginx拦截到数据的时间戳，这个都可以改
环形数组用来存入一小时内每分钟的条数，定时上报就行
补时数组比较麻烦，因为要考虑回补数据
要把老时间的数据补在那个位置上
这里搞定，就能知道每个机器有没有丢数据（可以更具日志上的时间，也可以按读取的时间）
接下来就是数据落盘
当然在改组件内部，改源码要有好的代码功底，不然线程消耗会有问题
然后有了所有监控数据，做什么都可以。比如同比环比，趋势预测，以及告警和其他
上面那层就不说了，五花八门一个大盘
很多中间件本省自带metric，但是很多都不支持业务上的metric
比如说kafka的offset，但是不能做到基于业务的metric，想要同步起来，还是要在一个系统里
比如flume，本身又分为source、channel，sink，我想把这些组件和kafka的监控结合起来，以及套用其他东西
最后就能看到他们需要多少数据，经过大数据各个环节有多少条，最后输出多少条，每条数据到达组件的时间点
能监控数据同环比，有异常能第一时间电话告警
 

 
